  CTO_FROM               : nvidia/cuda:9.2-cudnn7-devel-ubuntu18.04
docker build  \
  --build-arg CTO_FROM="nvidia/cuda:9.2-cudnn7-devel-ubuntu18.04" \
  --build-arg CTO_TENSORFLOW_VERSION="1.15.5" \
  --build-arg CTO_OPENCV_VERSION="3.4.14" \
  --build-arg CTO_NUMPROC="32" \
  --build-arg CTO_CUDA_APT="cuda-npp-9.2 cuda-cublas-9.0 cuda-cufft-9.2 cuda-libraries-9.2 cuda-npp-dev-9.2 cuda-cublas-dev-9.0 cuda-cufft-dev-9.2 cuda-libraries-dev-9.2" \
  --build-arg CTO_CUDA_BUILD="-D WITH_CUDA=ON -D CUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda -D CMAKE_LIBRARY_PATH=/usr/local/cuda/lib64/stubs -D CUDA_FAST_MATH=1 -D WITH_CUBLAS=1 -DWITH_CUDNN=ON -DOPENCV_DNN_CUDA=ON -DCUDA_ARCH_BIN=6.0,6.1,7.0 -D WITH_NVCUVID=ON" \
  --build-arg LATEST_BAZELISK="1.7.5" \
  --build-arg LATEST_BAZEL="3.7.2" \
  --build-arg CTO_TF_CUDNN="yes" \
  --build-arg CTO_TF_OPT="v1" \
  --build-arg CTO_TF_KERAS="keras==2.3.1 tensorflow<2" \
  --build-arg CTO_TF_PYTHON="3.8" \
  --build-arg CTO_TF_NUMPY="numpy<1.19.0" \
  --build-arg CTO_DNN_ARCH="6.0,6.1,7.0" \
  --build-arg CTO_CUDA11_APT_XTRA="" \
  --build-arg CTO_PYTORCH="torch==1.7.1+cu92 torchvision==0.8.2+cu92 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html" \
  --tag="datamachines/cudnn_tensorflow_opencv:9.2_1.15.5_3.4.14-20210420" \
  -f ubuntu18.04/Dockerfile \
  .
[pip list]
Package              Version
-------------------- ---------------
absl-py              0.12.0
argon2-cffi          20.1.0
astor                0.8.1
async-generator      1.10
attrs                20.3.0
autovizwidget        0.18.0
backcall             0.2.0
bleach               3.3.0
certifi              2020.12.5
cffi                 1.14.5
chardet              4.0.0
cycler               0.10.0
decorator            4.4.2
defusedxml           0.7.1
entrypoints          0.3
future               0.18.2
gast                 0.2.2
google-pasta         0.2.0
grpcio               1.37.0
h5py                 2.10.0
hdijupyterutils      0.18.0
idna                 2.10
imageio              2.9.0
imageio-ffmpeg       0.4.3
ipykernel            5.5.3
ipython              7.22.0
ipython-genutils     0.2.0
ipywidgets           7.6.3
jedi                 0.18.0
Jinja2               2.11.3
joblib               1.0.1
jsonschema           3.2.0
jupyter              1.0.0
jupyter-client       6.1.12
jupyter-console      6.4.0
jupyter-core         4.7.1
jupyterlab-pygments  0.1.2
jupyterlab-widgets   1.0.0
Keras                2.3.1
Keras-Applications   1.0.8
Keras-Preprocessing  1.1.2
kiwisolver           1.3.1
lxml                 4.6.3
Markdown             3.3.4
MarkupSafe           1.1.1
matplotlib           3.4.1
mistune              0.8.4
mock                 4.0.3
moviepy              1.0.3
nbclient             0.5.3
nbconvert            6.0.7
nbformat             5.1.3
nest-asyncio         1.5.1
networkx             2.5.1
nose                 1.3.7
notebook             6.3.0
numpy                1.18.5
opt-einsum           3.3.0
packaging            20.9
pandas               1.2.4
pandocfilters        1.4.3
parso                0.8.2
pexpect              4.8.0
pickleshare          0.7.5
Pillow               8.2.0
pip                  21.0.1
plotly               4.14.3
proglog              0.1.9
prometheus-client    0.10.1
prompt-toolkit       3.0.18
protobuf             3.15.8
ptyprocess           0.7.0
pycparser            2.20
Pygments             2.8.1
pygobject            3.26.1
pyparsing            2.4.7
pyrsistent           0.17.3
python-apt           1.6.5+ubuntu0.5
python-dateutil      2.8.1
pytz                 2021.1
PyWavelets           1.1.1
PyYAML               5.4.1
pyzmq                22.0.3
qtconsole            5.0.3
QtPy                 1.9.0
requests             2.25.1
retrying             1.3.3
scikit-image         0.18.1
scikit-learn         0.24.1
scipy                1.6.2
Send2Trash           1.5.0
setuptools           56.0.0
six                  1.15.0
tensorboard          1.15.0
tensorflow           1.15.5
tensorflow-estimator 1.15.1
termcolor            1.1.0
terminado            0.9.4
testpath             0.4.4
threadpoolctl        2.1.0
tifffile             2021.4.8
torch                1.7.1+cu92
torchaudio           0.7.2
torchvision          0.8.2+cu92
tornado              6.1
tqdm                 4.60.0
traitlets            5.0.5
typing-extensions    3.7.4.3
unattended-upgrades  0.1
urllib3              1.26.4
wcwidth              0.2.5
webencodings         0.5.1
Werkzeug             1.0.1
wheel                0.36.2
widgetsnbextension   3.5.1
wrapt                1.12.1

-- Confirming OpenCV Python is installed. Version: 3.4.14

-------------------------------------------------------

[TensorFlow build information]
--- Tensorflow Build --- 
** CUDNN requested
-- Environment variables set:
TF_CUDA_CLANG=0
TF_CUDA_COMPUTE_CAPABILITIES=6.0,6.1,7.0
TF_CUDA_VERSION=9.2
TF_CUDNN_VERSION=7
TF_DOWNLOAD_CLANG=0
TF_DOWNLOAD_MKL=0
TF_ENABLE_XLA=0
TF_NEED_AWS=0
TF_NEED_COMPUTECPP=0
TF_NEED_CUDA=1
TF_NEED_GCP=0
TF_NEED_GDR=0
TF_NEED_HDFS=0
TF_NEED_JEMALLOC=1
TF_NEED_KAFKA=0
TF_NEED_MKL=0
TF_NEED_MPI=0
TF_NEED_OPENCL=0
TF_NEED_OPENCL_SYCL=0
TF_NEED_ROCM=0
TF_NEED_S3=0
TF_NEED_TENSORRT=0
TF_NEED_VERBS=0
TF_SET_ANDROID_WORKSPACE=0
GCC_HOST_COMPILER_PATH=/usr/bin/gcc
CC_OPT_FLAGS=
PYTHON_BIN_PATH=/usr/local/bin/python
PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages
-- ./configure output:
You have bazel 0.26.1 installed.
Found CUDA 9.2 in:
    /usr/local/cuda-9.2/lib64
    /usr/local/cuda-9.2/include
Found cuDNN 7 in:
    /usr/lib/x86_64-linux-gnu
    /usr/include


Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native -Wno-sign-compare]: 

Preconfigured Bazel build configs. You can use any of the below by adding "--config=<>" to your build command. See .bazelrc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
	--config=gdr         	# Build with GDR support.
	--config=verbs       	# Build with libverbs support.
	--config=ngraph      	# Build with Intel nGraph support.
	--config=numa        	# Build with NUMA support.
	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.
	--config=v2          	# Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
	--config=noaws       	# Disable AWS S3 filesystem support.
	--config=nogcp       	# Disable GCP support.
	--config=nohdfs      	# Disable HDFS support.
	--config=noignite    	# Disable Apache Ignite support.
	--config=nokafka     	# Disable Apache Kafka support.
	--config=nonccl      	# Disable NVIDIA NCCL support.
Configuration finished
-- bazel command to run:
bazel build --verbose_failures --config=opt --config=v1 --config=cuda //tensorflow/tools/pip_package:build_pip_package
-- TensorFlow building time (in seconds): 3193

-------------------------------------------------------

[Extra information]
FOUND_UBUNTU: 18.04
FOUND_CUDNN: 7.6.5
*** Tensorflow version   :  1.15.5
*** Tensorflow Keras     :  2.2.4-tf
*** TF Builf with cuda   :  True
*** TF compile flags     :  ['-I/usr/local/lib/python3.8/dist-packages/tensorflow_core/include', '-D_GLIBCXX_USE_CXX11_ABI=1']
*** TF include           :  /usr/local/lib/python3.8/dist-packages/tensorflow_core/include
*** TF lib               :  /usr/local/lib/python3.8/dist-packages/tensorflow_core
*** TF link flags        :  ['-L/usr/local/lib/python3.8/dist-packages/tensorflow_core', '-l:libtensorflow_framework.so.1']
*** OpenCV version       :  3.4.14
*** Keras version        :  2.3.1
*** PyTorch version      :  1.7.1+cu92
   *** PyTorch Audio     :  0.7.2
   *** PyTorch Vision    :  0.8.2+cu92
*** pandas version       :  1.2.4
*** scikit-learn version :  0.24.1

(!! the following is build device specific, and here only to confirm hardware availability, ignore !!)
--- All seen hardware    :
 [name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 14747927480222306310
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 23336304640
locality {
  bus_id: 1
  links {
  }
}
incarnation: 16284708293881807783
physical_device_desc: "device: 0, name: GeForce RTX 3090, pci bus id: 0000:08:00.0, compute capability: 8.6"
]
--- TF GPU Available     :
 [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
